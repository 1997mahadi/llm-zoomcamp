#!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py


import minsearch


import json 


with open('documents.json', 'rt') as f_in:
    docs_raw = json.load(f_in)


#print(docs_raw)


documents= []

for course_dict in docs_raw:
    for doc in course_dict['documents']:
        doc['course']=course_dict['course']
        documents.append(doc)
    


#documents


index=minsearch.Index(
    text_fields=["question", "text", "section"],
    keyword_fields= ["course"]
)


#q= 'the course has already started, can I still enroll?'





index.fit(documents)


#results


import  ollama


#!ollama pull phi3


#!ollama pull mistral


from openai import OpenAI


client = OpenAI(
    base_url='http://localhost:11434/v1',
    api_key='ollama'  # required, but unused
)


#print(prompt)


def search(query):
    boost = {'question': 3.0, 'section': 0.5}

    results=index.search(
        query = query,
        filter_dict={'course':'data-engineering-zoomcamp'},
        boost_dict=boost, 
        num_results=5
    )

    return results


def build_prompt(query, search_results):
    prompt_template = """
You're a course teaching assistant. Answer the QESTION based on the CONTEXT from the FAQ database. 
Use only the facts from the CONTEXT when answering the QUESTION. 

QUESTION : {question}

CONTEXT:
{context}
""".strip()

    context = ""
    
    for doc in search_results:
         context = context + f"section: {doc['section']}\nquestion: {doc['question']}\nanswer: {doc['text']}\n\n"
    
    prompt=prompt_template.format(question=query, context=context).strip()
    return prompt


def llm(prompt):
    response = client .chat.completions.create(
           model="phi3",
           messages=[{"role":"user", "content":prompt}]
    )
    
    return response.choices[0].message.content


query= 'how do I run kafka? '

def rag(query):
    search_results = search(query)
    prompt=build_prompt(query, search_results)
    answer= llm(prompt)
    return answer






rag(query)


documents[0]


from elasticsearch import Elasticsearch



es_client= Elasticsearch('http://localhost:9200')


index_settings= {
    "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0
    },
    "mappings": {
        "properties": {
            "text": {"type": "text"},
            "section": {"type": "text"},
            "question": {"type": "text"},
            "course": {"type": "keyword"} 
        }
    }
}

index_name = "course-questions"
es_client.indices.create(index= index_name , body=index_settings)


from tqdm.auto import tqdm


for doc in tqdm(documents) :
    es_client.index(index= index_name , document=doc )



